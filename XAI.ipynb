{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da115e91-99fc-43d8-92a1-adf3508b7abb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting eli5==0.11.0\n",
      "  Downloading eli5-0.11.0-py2.py3-none-any.whl.metadata (17 kB)\n",
      "Collecting scikit-learn==0.24.2\n",
      "  Downloading scikit-learn-0.24.2.tar.gz (7.5 MB)\n",
      "     ---------------------------------------- 0.0/7.5 MB ? eta -:--:--\n",
      "     -- ------------------------------------- 0.5/7.5 MB 2.4 MB/s eta 0:00:03\n",
      "     ------ --------------------------------- 1.3/7.5 MB 3.5 MB/s eta 0:00:02\n",
      "     --------- ------------------------------ 1.8/7.5 MB 3.0 MB/s eta 0:00:02\n",
      "     ----------- ---------------------------- 2.1/7.5 MB 2.4 MB/s eta 0:00:03\n",
      "     ----------- ---------------------------- 2.1/7.5 MB 2.4 MB/s eta 0:00:03\n",
      "     ----------- ---------------------------- 2.1/7.5 MB 2.4 MB/s eta 0:00:03\n",
      "     ------------ --------------------------- 2.4/7.5 MB 1.7 MB/s eta 0:00:04\n",
      "     ------------ --------------------------- 2.4/7.5 MB 1.7 MB/s eta 0:00:04\n",
      "     ------------- -------------------------- 2.6/7.5 MB 1.4 MB/s eta 0:00:04\n",
      "     --------------- ------------------------ 2.9/7.5 MB 1.4 MB/s eta 0:00:04\n",
      "     ---------------- ----------------------- 3.1/7.5 MB 1.3 MB/s eta 0:00:04\n",
      "     ------------------ --------------------- 3.4/7.5 MB 1.3 MB/s eta 0:00:04\n",
      "     ------------------- -------------------- 3.7/7.5 MB 1.3 MB/s eta 0:00:03\n",
      "     -------------------- ------------------- 3.9/7.5 MB 1.3 MB/s eta 0:00:03\n",
      "     ---------------------- ----------------- 4.2/7.5 MB 1.3 MB/s eta 0:00:03\n",
      "     ----------------------- ---------------- 4.5/7.5 MB 1.3 MB/s eta 0:00:03\n",
      "     ------------------------- -------------- 4.7/7.5 MB 1.3 MB/s eta 0:00:03\n",
      "     -------------------------- ------------- 5.0/7.5 MB 1.3 MB/s eta 0:00:03\n",
      "     --------------------------- ------------ 5.2/7.5 MB 1.3 MB/s eta 0:00:02\n",
      "     ------------------------------ --------- 5.8/7.5 MB 1.3 MB/s eta 0:00:02\n",
      "     -------------------------------- ------- 6.0/7.5 MB 1.3 MB/s eta 0:00:02\n",
      "     --------------------------------- ------ 6.3/7.5 MB 1.3 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 6.6/7.5 MB 1.4 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 6.6/7.5 MB 1.4 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 6.8/7.5 MB 1.3 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 7.1/7.5 MB 1.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 7.5/7.5 MB 1.3 MB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: still running...\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'error'\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~ (C:\\Users\\atray\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  Preparing metadata (pyproject.toml) did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [72 lines of output]\n",
      "  <string>:17: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n",
      "  Partial import of sklearn during the build process.\n",
      "  <string>:116: DeprecationWarning:\n",
      "  \n",
      "    `numpy.distutils` is deprecated since NumPy 1.23.0, as a result\n",
      "    of the deprecation of `distutils` itself. It will be removed for\n",
      "    Python >= 3.12. For older Python versions it will remain present.\n",
      "    It is recommended to use `setuptools < 60.0` for those Python versions.\n",
      "    For more details, see:\n",
      "      https://numpy.org/devdocs/reference/distutils_status_migration.html\n",
      "  \n",
      "  \n",
      "  C:\\Users\\atray\\AppData\\Local\\Temp\\pip-build-env-mmii2d18\\overlay\\Lib\\site-packages\\setuptools\\dist.py:759: SetuptoolsDeprecationWarning: License classifiers are deprecated.\n",
      "  !!\n",
      "  \n",
      "          ********************************************************************************\n",
      "          Please consider removing the following classifiers in favor of a SPDX license expression:\n",
      "  \n",
      "          License :: OSI Approved\n",
      "  \n",
      "          See https://packaging.python.org/en/latest/guides/writing-pyproject-toml/#license for details.\n",
      "          ********************************************************************************\n",
      "  \n",
      "  !!\n",
      "    self._finalize_license_expression()\n",
      "  INFO: No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  Traceback (most recent call last):\n",
      "    File \"C:\\Users\\atray\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 389, in <module>\n",
      "      main()\n",
      "    File \"C:\\Users\\atray\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 373, in main\n",
      "      json_out[\"return_val\"] = hook(**hook_input[\"kwargs\"])\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Users\\atray\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 175, in prepare_metadata_for_build_wheel\n",
      "      return hook(metadata_directory, config_settings)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Users\\atray\\AppData\\Local\\Temp\\pip-build-env-mmii2d18\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 377, in prepare_metadata_for_build_wheel\n",
      "      self.run_setup()\n",
      "    File \"C:\\Users\\atray\\AppData\\Local\\Temp\\pip-build-env-mmii2d18\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 522, in run_setup\n",
      "      super().run_setup(setup_script=setup_script)\n",
      "    File \"C:\\Users\\atray\\AppData\\Local\\Temp\\pip-build-env-mmii2d18\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 320, in run_setup\n",
      "      exec(code, locals())\n",
      "    File \"<string>\", line 301, in <module>\n",
      "    File \"<string>\", line 297, in setup_package\n",
      "    File \"C:\\Users\\atray\\AppData\\Local\\Temp\\pip-build-env-mmii2d18\\overlay\\Lib\\site-packages\\numpy\\distutils\\core.py\", line 135, in setup\n",
      "      config = configuration()\n",
      "               ^^^^^^^^^^^^^^^\n",
      "    File \"<string>\", line 188, in configuration\n",
      "    File \"C:\\Users\\atray\\AppData\\Local\\Temp\\pip-build-env-mmii2d18\\overlay\\Lib\\site-packages\\numpy\\distutils\\misc_util.py\", line 1041, in add_subpackage\n",
      "      config_list = self.get_subpackage(subpackage_name, subpackage_path,\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Users\\atray\\AppData\\Local\\Temp\\pip-build-env-mmii2d18\\overlay\\Lib\\site-packages\\numpy\\distutils\\misc_util.py\", line 1007, in get_subpackage\n",
      "      config = self._get_configuration_from_setup_py(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Users\\atray\\AppData\\Local\\Temp\\pip-build-env-mmii2d18\\overlay\\Lib\\site-packages\\numpy\\distutils\\misc_util.py\", line 949, in _get_configuration_from_setup_py\n",
      "      config = setup_module.configuration(*args)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Users\\atray\\AppData\\Local\\Temp\\pip-install-6i9rgd88\\scikit-learn_03788e91394c42cbb5aae96a5b4aad26\\sklearn\\setup.py\", line 83, in configuration\n",
      "      cythonize_extensions(top_path, config)\n",
      "    File \"C:\\Users\\atray\\AppData\\Local\\Temp\\pip-install-6i9rgd88\\scikit-learn_03788e91394c42cbb5aae96a5b4aad26\\sklearn\\_build_utils\\__init__.py\", line 45, in cythonize_extensions\n",
      "      basic_check_build()\n",
      "    File \"C:\\Users\\atray\\AppData\\Local\\Temp\\pip-install-6i9rgd88\\scikit-learn_03788e91394c42cbb5aae96a5b4aad26\\sklearn\\_build_utils\\pre_build_helpers.py\", line 106, in basic_check_build\n",
      "      compile_test_program(code)\n",
      "    File \"C:\\Users\\atray\\AppData\\Local\\Temp\\pip-install-6i9rgd88\\scikit-learn_03788e91394c42cbb5aae96a5b4aad26\\sklearn\\_build_utils\\pre_build_helpers.py\", line 66, in compile_test_program\n",
      "      ccompiler.compile(['test_program.c'], output_dir='objects',\n",
      "    File \"C:\\Users\\atray\\AppData\\Local\\Temp\\pip-build-env-mmii2d18\\overlay\\Lib\\site-packages\\setuptools\\_distutils\\compilers\\C\\msvc.py\", line 384, in compile\n",
      "      self.initialize()\n",
      "    File \"C:\\Users\\atray\\AppData\\Local\\Temp\\pip-build-env-mmii2d18\\overlay\\Lib\\site-packages\\setuptools\\_distutils\\compilers\\C\\msvc.py\", line 294, in initialize\n",
      "      vc_env = _get_vc_env(plat_spec)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Users\\atray\\AppData\\Local\\Temp\\pip-build-env-mmii2d18\\overlay\\Lib\\site-packages\\setuptools\\_distutils\\compilers\\C\\msvc.py\", line 155, in _get_vc_env\n",
      "      raise DistutilsPlatformError(\n",
      "  distutils.errors.DistutilsPlatformError: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: metadata-generation-failed\n",
      "\n",
      "Encountered error while generating package metadata.\n",
      "\n",
      "See above for output.\n",
      "\n",
      "note: This is an issue with the package mentioned above, not pip.\n",
      "hint: See above for details.\n"
     ]
    }
   ],
   "source": [
    "pip install eli5==0.11.0 scikit-learn==0.24.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8d025e88-2ea9-4e95-98d9-98468834291c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import shap\n",
    "import lime\n",
    "import lime.lime_tabular\n",
    "import joblib\n",
    "import pickle\n",
    "import os\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5050d74a-518b-43af-832c-dab514d58ede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model file not found. Please train a model first or specify the correct path.\n"
     ]
    }
   ],
   "source": [
    "class HNIDS_Explainer:\n",
    "    \"\"\"\n",
    "    Explainable AI (XAI) toolkit for HNIDS (Hybrid Network-based Intrusion Detection System).\n",
    "    Provides various methods to interpret and explain model decisions.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, hnids_model=None, X_train=None, y_train=None, X_test=None, y_test=None):\n",
    "        \"\"\"\n",
    "        Initialize the HNIDS Explainer with model and data.\n",
    "        \n",
    "        Args:\n",
    "            hnids_model: Trained HNIDS model\n",
    "            X_train: Training features\n",
    "            y_train: Training labels\n",
    "            X_test: Test features\n",
    "            y_test: Test labels\n",
    "        \"\"\"\n",
    "        self.hnids_model = hnids_model\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.X_test = X_test\n",
    "        self.y_test = y_test\n",
    "        self.explainers = {}\n",
    "        \n",
    "    def load_model(self, model_path):\n",
    "        \"\"\"\n",
    "        Load a previously saved HNIDS model.\n",
    "        \n",
    "        Args:\n",
    "            model_path: Path to the saved model file\n",
    "        \"\"\"\n",
    "        try:\n",
    "            with open(model_path, 'rb') as f:\n",
    "                self.hnids_model = pickle.load(f)\n",
    "            print(f\"Model loaded successfully from {model_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading model: {e}\")\n",
    "    \n",
    "    def load_data(self, X_train=None, y_train=None, X_test=None, y_test=None):\n",
    "        \"\"\"\n",
    "        Load data for explanation.\n",
    "        \n",
    "        Args:\n",
    "            X_train: Training features\n",
    "            y_train: Training labels\n",
    "            X_test: Test features\n",
    "            y_test: Test labels\n",
    "        \"\"\"\n",
    "        if X_train is not None:\n",
    "            self.X_train = X_train\n",
    "        if y_train is not None:\n",
    "            self.y_train = y_train\n",
    "        if X_test is not None:\n",
    "            self.X_test = X_test\n",
    "        if y_test is not None:\n",
    "            self.y_test = y_test\n",
    "    \n",
    "    def get_feature_importance(self, n_top_features=20, plot=True):\n",
    "        \"\"\"\n",
    "        Get feature importance using permutation importance method.\n",
    "        \n",
    "        Args:\n",
    "            n_top_features: Number of top features to display\n",
    "            plot: Whether to plot the feature importance\n",
    "            \n",
    "        Returns:\n",
    "            DataFrame with feature importance scores\n",
    "        \"\"\"\n",
    "        if self.hnids_model is None or self.X_test is None or self.y_test is None:\n",
    "            print(\"Model or test data not available. Please load model and data first.\")\n",
    "            return None\n",
    "        \n",
    "        try:\n",
    "            # Get the core Random Forest model from HNIDS\n",
    "            rf_model = self.hnids_model.irf_model\n",
    "            \n",
    "            # Get selected features if available\n",
    "            if hasattr(self.hnids_model, 'best_features') and self.hnids_model.best_features is not None:\n",
    "                feature_indices = np.where(self.hnids_model.best_features == 1)[0]\n",
    "                if hasattr(self.hnids_model, 'feature_names') and self.hnids_model.feature_names is not None:\n",
    "                    valid_indices = [idx for idx in feature_indices if idx < len(self.hnids_model.feature_names)]\n",
    "                    selected_features = [self.hnids_model.feature_names[idx] for idx in valid_indices]\n",
    "                    X_test_selected = self.X_test[selected_features]\n",
    "                else:\n",
    "                    # Use all features if feature names not available\n",
    "                    X_test_selected = self.X_test\n",
    "            else:\n",
    "                # Use all features if no feature selection\n",
    "                X_test_selected = self.X_test\n",
    "            \n",
    "            # Calculate permutation importance\n",
    "            perm_importance = permutation_importance(rf_model, X_test_selected, self.y_test, \n",
    "                                                   n_repeats=10, random_state=42, n_jobs=-1)\n",
    "            \n",
    "            # Create DataFrame with importance scores\n",
    "            feature_names = X_test_selected.columns\n",
    "            importance_df = pd.DataFrame({\n",
    "                'Feature': feature_names,\n",
    "                'Importance': perm_importance.importances_mean,\n",
    "                'Std_Dev': perm_importance.importances_std\n",
    "            })\n",
    "            \n",
    "            # Sort by importance\n",
    "            importance_df = importance_df.sort_values('Importance', ascending=False).reset_index(drop=True)\n",
    "            \n",
    "            # Plot feature importance\n",
    "            if plot:\n",
    "                plt.figure(figsize=(12, 8))\n",
    "                \n",
    "                # Take top N features\n",
    "                plot_df = importance_df.head(n_top_features).copy()\n",
    "                \n",
    "                # Plot\n",
    "                ax = sns.barplot(x='Importance', y='Feature', data=plot_df, \n",
    "                                palette='viridis', xerr=plot_df['Std_Dev'])\n",
    "                \n",
    "                plt.title('Feature Importance (Permutation Method)', fontsize=16)\n",
    "                plt.xlabel('Importance Score', fontsize=14)\n",
    "                plt.ylabel('Features', fontsize=14)\n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "            \n",
    "            return importance_df\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error calculating feature importance: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def initialize_shap_explainer(self):\n",
    "        \"\"\"\n",
    "        Initialize SHAP explainer for the model.\n",
    "        \"\"\"\n",
    "        if self.hnids_model is None or self.X_train is None:\n",
    "            print(\"Model or training data not available. Please load model and data first.\")\n",
    "            return\n",
    "        \n",
    "        try:\n",
    "            # Get the core Random Forest model from HNIDS\n",
    "            rf_model = self.hnids_model.irf_model\n",
    "            \n",
    "            # Get selected features if available\n",
    "            if hasattr(self.hnids_model, 'best_features') and self.hnids_model.best_features is not None:\n",
    "                feature_indices = np.where(self.hnids_model.best_features == 1)[0]\n",
    "                if hasattr(self.hnids_model, 'feature_names') and self.hnids_model.feature_names is not None:\n",
    "                    valid_indices = [idx for idx in feature_indices if idx < len(self.hnids_model.feature_names)]\n",
    "                    selected_features = [self.hnids_model.feature_names[idx] for idx in valid_indices]\n",
    "                    X_train_selected = self.X_train[selected_features]\n",
    "                else:\n",
    "                    # Use all features if feature names not available\n",
    "                    X_train_selected = self.X_train\n",
    "            else:\n",
    "                # Use all features if no feature selection\n",
    "                X_train_selected = self.X_train\n",
    "            \n",
    "            # Create a smaller sample for faster SHAP explanation\n",
    "            X_sample = X_train_selected.sample(min(1000, len(X_train_selected)), random_state=42)\n",
    "            \n",
    "            # Initialize SHAP explainer\n",
    "            self.explainers['shap'] = shap.TreeExplainer(rf_model)\n",
    "            print(\"SHAP explainer initialized successfully.\")\n",
    "            \n",
    "            return X_sample\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error initializing SHAP explainer: {e}\")\n",
    "    \n",
    "    def global_shap_explanation(self, max_display=20):\n",
    "        \"\"\"\n",
    "        Provide global SHAP explanation for the model.\n",
    "        \n",
    "        Args:\n",
    "            max_display: Maximum number of features to display\n",
    "        \"\"\"\n",
    "        if 'shap' not in self.explainers:\n",
    "            X_sample = self.initialize_shap_explainer()\n",
    "            if X_sample is None:\n",
    "                return\n",
    "        else:\n",
    "            # Get selected features\n",
    "            if hasattr(self.hnids_model, 'best_features') and self.hnids_model.best_features is not None:\n",
    "                feature_indices = np.where(self.hnids_model.best_features == 1)[0]\n",
    "                if hasattr(self.hnids_model, 'feature_names') and self.hnids_model.feature_names is not None:\n",
    "                    valid_indices = [idx for idx in feature_indices if idx < len(self.hnids_model.feature_names)]\n",
    "                    selected_features = [self.hnids_model.feature_names[idx] for idx in valid_indices]\n",
    "                    X_sample = self.X_train[selected_features].sample(min(1000, len(self.X_train)), random_state=42)\n",
    "                else:\n",
    "                    X_sample = self.X_train.sample(min(1000, len(self.X_train)), random_state=42)\n",
    "            else:\n",
    "                X_sample = self.X_train.sample(min(1000, len(self.X_train)), random_state=42)\n",
    "        \n",
    "        try:\n",
    "            # Calculate SHAP values\n",
    "            shap_values = self.explainers['shap'].shap_values(X_sample)\n",
    "            \n",
    "            # Plot summary\n",
    "            plt.figure(figsize=(12, 10))\n",
    "            \n",
    "            # For binary classification, we need the SHAP values for class 1 (intrusion)\n",
    "            if isinstance(shap_values, list) and len(shap_values) > 1:\n",
    "                shap_values_to_plot = shap_values[1]  # Class 1 (intrusion)\n",
    "                shap.summary_plot(shap_values_to_plot, X_sample, max_display=max_display, \n",
    "                                show=False, plot_size=(12, 10))\n",
    "            else:\n",
    "                shap.summary_plot(shap_values, X_sample, max_display=max_display, \n",
    "                                show=False, plot_size=(12, 10))\n",
    "            \n",
    "            plt.title('SHAP Feature Importance', fontsize=16)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "            # Plot bar summary\n",
    "            plt.figure(figsize=(12, 8))\n",
    "            \n",
    "            if isinstance(shap_values, list) and len(shap_values) > 1:\n",
    "                shap.summary_plot(shap_values_to_plot, X_sample, plot_type=\"bar\", \n",
    "                                max_display=max_display, show=False, plot_size=(12, 8))\n",
    "            else:\n",
    "                shap.summary_plot(shap_values, X_sample, plot_type=\"bar\", \n",
    "                                max_display=max_display, show=False, plot_size=(12, 8))\n",
    "            \n",
    "            plt.title('SHAP Mean Absolute Value (Impact on Model Output)', fontsize=16)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error in SHAP explanation: {e}\")\n",
    "    \n",
    "    def local_shap_explanation(self, instance_idx, force_plot=False):\n",
    "        \"\"\"\n",
    "        Provide local SHAP explanation for a specific instance.\n",
    "        \n",
    "        Args:\n",
    "            instance_idx: Index of the instance to explain\n",
    "            force_plot: Whether to create a force plot\n",
    "        \"\"\"\n",
    "        if 'shap' not in self.explainers:\n",
    "            X_sample = self.initialize_shap_explainer()\n",
    "            if X_sample is None:\n",
    "                return\n",
    "        \n",
    "        try:\n",
    "            # Get selected features if available\n",
    "            if hasattr(self.hnids_model, 'best_features') and self.hnids_model.best_features is not None:\n",
    "                feature_indices = np.where(self.hnids_model.best_features == 1)[0]\n",
    "                if hasattr(self.hnids_model, 'feature_names') and self.hnids_model.feature_names is not None:\n",
    "                    valid_indices = [idx for idx in feature_indices if idx < len(self.hnids_model.feature_names)]\n",
    "                    selected_features = [self.hnids_model.feature_names[idx] for idx in valid_indices]\n",
    "                    instance = self.X_test[selected_features].iloc[instance_idx:instance_idx+1]\n",
    "                else:\n",
    "                    instance = self.X_test.iloc[instance_idx:instance_idx+1]\n",
    "            else:\n",
    "                instance = self.X_test.iloc[instance_idx:instance_idx+1]\n",
    "            \n",
    "            # Get true label and prediction\n",
    "            true_label = self.y_test.iloc[instance_idx]\n",
    "            prediction = self.hnids_model.predict(pd.DataFrame(instance).reset_index(drop=True))[0]\n",
    "            \n",
    "            # Calculate SHAP values\n",
    "            shap_values = self.explainers['shap'].shap_values(instance)\n",
    "            \n",
    "            # For binary classification\n",
    "            if isinstance(shap_values, list) and len(shap_values) > 1:\n",
    "                print(f\"Instance {instance_idx}:\")\n",
    "                print(f\"True Label: {true_label} (0=Normal, 1=Intrusion)\")\n",
    "                print(f\"Prediction: {prediction} (0=Normal, 1=Intrusion)\")\n",
    "                \n",
    "                # Generate waterfall plot for the predicted class\n",
    "                plt.figure(figsize=(12, 8))\n",
    "                shap.waterfall_plot(shap.Explanation(\n",
    "                    values=shap_values[prediction][0], \n",
    "                    base_values=self.explainers['shap'].expected_value[prediction],\n",
    "                    data=instance.values[0],\n",
    "                    feature_names=instance.columns.tolist()\n",
    "                ), max_display=20, show=False)\n",
    "                plt.title(f'SHAP Waterfall Plot for Instance {instance_idx}', fontsize=16)\n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "                \n",
    "                # Generate force plot if requested\n",
    "                if force_plot:\n",
    "                    shap.force_plot(\n",
    "                        self.explainers['shap'].expected_value[prediction],\n",
    "                        shap_values[prediction][0],\n",
    "                        instance.iloc[0],\n",
    "                        matplotlib=True,\n",
    "                        show=False\n",
    "                    )\n",
    "                    plt.title(f'SHAP Force Plot for Instance {instance_idx}', fontsize=16)\n",
    "                    plt.tight_layout()\n",
    "                    plt.show()\n",
    "            else:\n",
    "                print(f\"Instance {instance_idx}:\")\n",
    "                print(f\"True Label: {true_label} (0=Normal, 1=Intrusion)\")\n",
    "                print(f\"Prediction: {prediction} (0=Normal, 1=Intrusion)\")\n",
    "                \n",
    "                # Generate waterfall plot\n",
    "                plt.figure(figsize=(12, 8))\n",
    "                shap.waterfall_plot(shap.Explanation(\n",
    "                    values=shap_values[0], \n",
    "                    base_values=self.explainers['shap'].expected_value,\n",
    "                    data=instance.values[0],\n",
    "                    feature_names=instance.columns.tolist()\n",
    "                ), max_display=20, show=False)\n",
    "                plt.title(f'SHAP Waterfall Plot for Instance {instance_idx}', fontsize=16)\n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "                \n",
    "                # Generate force plot if requested\n",
    "                if force_plot:\n",
    "                    shap.force_plot(\n",
    "                        self.explainers['shap'].expected_value,\n",
    "                        shap_values[0],\n",
    "                        instance.iloc[0],\n",
    "                        matplotlib=True,\n",
    "                        show=False\n",
    "                    )\n",
    "                    plt.title(f'SHAP Force Plot for Instance {instance_idx}', fontsize=16)\n",
    "                    plt.tight_layout()\n",
    "                    plt.show()\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\"Error in local SHAP explanation: {e}\")\n",
    "    \n",
    "    def initialize_lime_explainer(self):\n",
    "        \"\"\"\n",
    "        Initialize LIME explainer for the model.\n",
    "        \"\"\"\n",
    "        if self.hnids_model is None or self.X_train is None:\n",
    "            print(\"Model or training data not available. Please load model and data first.\")\n",
    "            return\n",
    "        \n",
    "        try:\n",
    "            # Get selected features if available\n",
    "            if hasattr(self.hnids_model, 'best_features') and self.hnids_model.best_features is not None:\n",
    "                feature_indices = np.where(self.hnids_model.best_features == 1)[0]\n",
    "                if hasattr(self.hnids_model, 'feature_names') and self.hnids_model.feature_names is not None:\n",
    "                    valid_indices = [idx for idx in feature_indices if idx < len(self.hnids_model.feature_names)]\n",
    "                    selected_features = [self.hnids_model.feature_names[idx] for idx in valid_indices]\n",
    "                    X_train_selected = self.X_train[selected_features]\n",
    "                else:\n",
    "                    X_train_selected = self.X_train\n",
    "            else:\n",
    "                X_train_selected = self.X_train\n",
    "            \n",
    "            # Initialize LIME explainer\n",
    "            self.explainers['lime'] = lime.lime_tabular.LimeTabularExplainer(\n",
    "                X_train_selected.values,\n",
    "                feature_names=X_train_selected.columns.tolist(),\n",
    "                class_names=['Normal', 'Intrusion'],\n",
    "                discretize_continuous=True,\n",
    "                mode='classification'\n",
    "            )\n",
    "            \n",
    "            print(\"LIME explainer initialized successfully.\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error initializing LIME explainer: {e}\")\n",
    "    \n",
    "    def local_lime_explanation(self, instance_idx, num_features=10):\n",
    "        \"\"\"\n",
    "        Provide local LIME explanation for a specific instance.\n",
    "        \n",
    "        Args:\n",
    "            instance_idx: Index of the instance to explain\n",
    "            num_features: Number of features to include in the explanation\n",
    "        \"\"\"\n",
    "        if 'lime' not in self.explainers:\n",
    "            self.initialize_lime_explainer()\n",
    "            if 'lime' not in self.explainers:\n",
    "                return\n",
    "        \n",
    "        try:\n",
    "            # Get the Random Forest model\n",
    "            rf_model = self.hnids_model.irf_model\n",
    "            \n",
    "            # Get selected features if available\n",
    "            if hasattr(self.hnids_model, 'best_features') and self.hnids_model.best_features is not None:\n",
    "                feature_indices = np.where(self.hnids_model.best_features == 1)[0]\n",
    "                if hasattr(self.hnids_model, 'feature_names') and self.hnids_model.feature_names is not None:\n",
    "                    valid_indices = [idx for idx in feature_indices if idx < len(self.hnids_model.feature_names)]\n",
    "                    selected_features = [self.hnids_model.feature_names[idx] for idx in valid_indices]\n",
    "                    instance = self.X_test[selected_features].iloc[instance_idx].values\n",
    "                    feature_names = selected_features\n",
    "                else:\n",
    "                    instance = self.X_test.iloc[instance_idx].values\n",
    "                    feature_names = self.X_test.columns.tolist()\n",
    "            else:\n",
    "                instance = self.X_test.iloc[instance_idx].values\n",
    "                feature_names = self.X_test.columns.tolist()\n",
    "            \n",
    "            # Get true label and prediction\n",
    "            true_label = self.y_test.iloc[instance_idx]\n",
    "            prediction_fn = lambda x: rf_model.predict_proba(x)\n",
    "            \n",
    "            # Generate LIME explanation\n",
    "            explanation = self.explainers['lime'].explain_instance(\n",
    "                instance, prediction_fn, num_features=num_features\n",
    "            )\n",
    "            \n",
    "            # Display explanation\n",
    "            print(f\"Instance {instance_idx}:\")\n",
    "            print(f\"True Label: {true_label} (0=Normal, 1=Intrusion)\")\n",
    "            predicted_prob = rf_model.predict_proba([instance])[0]\n",
    "            predicted_class = np.argmax(predicted_prob)\n",
    "            print(f\"Predicted: {predicted_class} (0=Normal, 1=Intrusion)\")\n",
    "            print(f\"Prediction Probabilities: Normal={predicted_prob[0]:.4f}, Intrusion={predicted_prob[1]:.4f}\")\n",
    "            \n",
    "            # Plot explanation\n",
    "            plt.figure(figsize=(12, 8))\n",
    "            explanation.as_pyplot_figure(label=1)  # Plot for intrusion class\n",
    "            plt.title(f'LIME Explanation for Instance {instance_idx}', fontsize=16)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error in LIME explanation: {e}\")\n",
    "    \n",
    "    def partial_dependence_plot(self, feature_names, grid_resolution=20, max_plots=6):\n",
    "        \"\"\"\n",
    "        Create partial dependence plots for selected features.\n",
    "        \n",
    "        Args:\n",
    "            feature_names: List of feature names to plot\n",
    "            grid_resolution: Resolution of the grid\n",
    "            max_plots: Maximum number of plots to display\n",
    "        \"\"\"\n",
    "        if self.hnids_model is None or self.X_train is None:\n",
    "            print(\"Model or training data not available. Please load model and data first.\")\n",
    "            return\n",
    "        \n",
    "        try:\n",
    "            # Get the Random Forest model\n",
    "            rf_model = self.hnids_model.irf_model\n",
    "            \n",
    "            # Get selected features if available\n",
    "            if hasattr(self.hnids_model, 'best_features') and self.hnids_model.best_features is not None:\n",
    "                feature_indices = np.where(self.hnids_model.best_features == 1)[0]\n",
    "                if hasattr(self.hnids_model, 'feature_names') and self.hnids_model.feature_names is not None:\n",
    "                    valid_indices = [idx for idx in feature_indices if idx < len(self.hnids_model.feature_names)]\n",
    "                    selected_features = [self.hnids_model.feature_names[idx] for idx in valid_indices]\n",
    "                    X_data = self.X_train[selected_features]\n",
    "                else:\n",
    "                    X_data = self.X_train\n",
    "            else:\n",
    "                X_data = self.X_train\n",
    "            \n",
    "            # Validate feature names\n",
    "            valid_feature_names = []\n",
    "            for feature in feature_names:\n",
    "                if feature in X_data.columns:\n",
    "                    valid_feature_names.append(feature)\n",
    "                else:\n",
    "                    print(f\"Warning: Feature '{feature}' not found in the data.\")\n",
    "            \n",
    "            if not valid_feature_names:\n",
    "                print(\"No valid features to plot.\")\n",
    "                return\n",
    "            \n",
    "            # Limit the number of plots\n",
    "            valid_feature_names = valid_feature_names[:max_plots]\n",
    "            \n",
    "            # Calculate feature indices\n",
    "            feature_indices = [list(X_data.columns).index(feat) for feat in valid_feature_names]\n",
    "            \n",
    "            # Create partial dependence plots\n",
    "            from sklearn.inspection import partial_dependence\n",
    "            \n",
    "            # Set up the figure\n",
    "            n_features = len(valid_feature_names)\n",
    "            n_cols = min(3, n_features)\n",
    "            n_rows = (n_features + n_cols - 1) // n_cols\n",
    "            \n",
    "            fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 5 * n_rows))\n",
    "            if n_features == 1:\n",
    "                axes = np.array([axes])  # Make it indexable for a single plot\n",
    "            axes = axes.flatten()\n",
    "            \n",
    "            # Generate plots\n",
    "            for i, (feature_idx, feature_name) in enumerate(zip(feature_indices, valid_feature_names)):\n",
    "                # Calculate partial dependence\n",
    "                pdp = partial_dependence(\n",
    "                    rf_model, X_data, features=[feature_idx], \n",
    "                    kind='average', grid_resolution=grid_resolution\n",
    "                )\n",
    "                \n",
    "                # Plot\n",
    "                feature_values = pdp['values'][0]\n",
    "                avg_effect = pdp['average'][0]\n",
    "                \n",
    "                ax = axes[i]\n",
    "                ax.plot(feature_values, avg_effect, 'b-', linewidth=2)\n",
    "                ax.set_title(f'Partial Dependence for {feature_name}', fontsize=12)\n",
    "                ax.set_xlabel(feature_name, fontsize=10)\n",
    "                ax.set_ylabel('Average Prediction (Probability)', fontsize=10)\n",
    "                ax.grid(True, alpha=0.3)\n",
    "            \n",
    "            # Hide any unused axes\n",
    "            for j in range(i+1, len(axes)):\n",
    "                axes[j].set_visible(False)\n",
    "                \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error creating partial dependence plots: {e}\")\n",
    "    \n",
    "    def feature_interaction_plot(self, feature1, feature2):\n",
    "        \"\"\"\n",
    "        Create a 2D partial dependence plot to show interaction between two features.\n",
    "        \n",
    "        Args:\n",
    "            feature1: First feature name\n",
    "            feature2: Second feature name\n",
    "        \"\"\"\n",
    "        if self.hnids_model is None or self.X_train is None:\n",
    "            print(\"Model or training data not available. Please load model and data first.\")\n",
    "            return\n",
    "        \n",
    "        try:\n",
    "            # Get the Random Forest model\n",
    "            rf_model = self.hnids_model.irf_model\n",
    "            \n",
    "            # Get selected features if available\n",
    "            if hasattr(self.hnids_model, 'best_features') and self.hnids_model.best_features is not None:\n",
    "                feature_indices = np.where(self.hnids_model.best_features == 1)[0]\n",
    "                if hasattr(self.hnids_model, 'feature_names') and self.hnids_model.feature_names is not None:\n",
    "                    valid_indices = [idx for idx in feature_indices if idx < len(self.hnids_model.feature_names)]\n",
    "                    selected_features = [self.hnids_model.feature_names[idx] for idx in valid_indices]\n",
    "                    X_data = self.X_train[selected_features]\n",
    "                else:\n",
    "                    X_data = self.X_train\n",
    "            else:\n",
    "                X_data = self.X_train\n",
    "            \n",
    "            # Validate features\n",
    "            if feature1 not in X_data.columns:\n",
    "                print(f\"Feature '{feature1}' not found in the data.\")\n",
    "                return\n",
    "            if feature2 not in X_data.columns:\n",
    "                print(f\"Feature '{feature2}' not found in the data.\")\n",
    "                return\n",
    "            \n",
    "            # Get feature indices\n",
    "            feature1_idx = list(X_data.columns).index(feature1)\n",
    "            feature2_idx = list(X_data.columns).index(feature2)\n",
    "            \n",
    "            # Calculate 2D partial dependence\n",
    "            from sklearn.inspection import partial_dependence\n",
    "            \n",
    "            pdp = partial_dependence(\n",
    "                rf_model, X_data, features=[(feature1_idx, feature2_idx)], \n",
    "                kind='average', grid_resolution=20\n",
    "            )\n",
    "            \n",
    "            # Extract data for plotting\n",
    "            XX, YY = np.meshgrid(pdp['values'][0][0], pdp['values'][0][1])\n",
    "            Z = pdp['average'][0].T\n",
    "            \n",
    "            # Create the plot\n",
    "            fig, ax = plt.subplots(figsize=(10, 8))\n",
    "            \n",
    "            # Contour plot\n",
    "            contour = ax.contourf(XX, YY, Z, cmap='viridis', alpha=0.8)\n",
    "            \n",
    "            # Add colorbar\n",
    "            cbar = plt.colorbar(contour, ax=ax)\n",
    "            cbar.set_label('Average Prediction (Probability)', fontsize=12)\n",
    "            \n",
    "            # Set labels and title\n",
    "            ax.set_xlabel(feature1, fontsize=12)\n",
    "            ax.set_ylabel(feature2, fontsize=12)\n",
    "            ax.set_title(f'Interaction Effect between {feature1} and {feature2}', fontsize=14)\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error creating feature interaction plot: {e}\")\n",
    "    \n",
    "    def plot_confusion_matrix(self, normalized=True):\n",
    "        \"\"\"\n",
    "        Plot confusion matrix for the model's predictions.\n",
    "        \n",
    "        Args:\n",
    "            normalized: Whether to normalize the confusion matrix\n",
    "        \"\"\"\n",
    "        if self.hnids_model is None or self.X_test is None or self.y_test is None:\n",
    "            print(\"Model or test data not available. Please load model and data first.\")\n",
    "            return\n",
    "        \n",
    "        try:\n",
    "            # Get predictions\n",
    "            y_pred = self.hnids_model.predict(self.X_test)\n",
    "            \n",
    "            # Calculate confusion matrix\n",
    "            cm = confusion_matrix(self.y_test, y_pred)\n",
    "            \n",
    "            # Normalize if requested\n",
    "            if normalized:\n",
    "                cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "                \n",
    "            # Create the plot\n",
    "            plt.figure(figsize=(10, 8))\n",
    "            sns.heatmap(cm, annot=True, fmt='.2f' if normalized else 'd', \n",
    "                      cmap='Blues', cbar=False, square=True)\n",
    "            \n",
    "            # Set labels and title\n",
    "            plt.xlabel('Predicted Label', fontsize=12)\n",
    "            plt.ylabel('True Label', fontsize=12)\n",
    "            title = 'Normalized Confusion Matrix' if normalized else 'Confusion Matrix'\n",
    "            plt.title(title, fontsize=14)\n",
    "            \n",
    "            # Set tick labels\n",
    "            plt.xticks([0.5, 1.5], ['Normal', 'Intrusion'])\n",
    "            plt.yticks([0.5, 1.5], ['Normal', 'Intrusion'])\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "            # Print classification report\n",
    "            print(\"Classification Report:\")\n",
    "            print(classification_report(self.y_test, y_pred, target_names=['Normal', 'Intrusion']))\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error plotting confusion matrix: {e}\")\n",
    "    \n",
    "    def get_detection_threshold_metrics(self, thresholds=None):\n",
    "        \"\"\"\n",
    "        Calculate model metrics at different detection thresholds.\n",
    "        \n",
    "        Args:\n",
    "            thresholds: List of threshold values to evaluate\n",
    "            \n",
    "        Returns:\n",
    "            DataFrame with metrics for each threshold\n",
    "        \"\"\"\n",
    "        if self.hnids_model is None or self.X_test is None or self.y_test is None:\n",
    "            print(\"Model or test data not available. Please load model and data first.\")\n",
    "            return None\n",
    "        \n",
    "        try:\n",
    "            # Get predictions\n",
    "            if not hasattr(self.hnids_model.irf_model, 'predict_proba'):\n",
    "                print(\"Model does not support probability predictions.\")\n",
    "                return None\n",
    "                \n",
    "            y_proba = self.hnids_model.irf_model.predict_proba(self.X_test)[:, 1]\n",
    "            \n",
    "            # Define thresholds if not provided\n",
    "            if thresholds is None:\n",
    "                thresholds = np.arange(0.1, 1.0, 0.1)\n",
    "                \n",
    "            # Calculate metrics for each threshold\n",
    "            results = []\n",
    "            \n",
    "            for threshold in thresholds:\n",
    "                y_pred = (y_proba >= threshold).astype(int)\n",
    "                \n",
    "                # Calculate metrics\n",
    "                tn, fp, fn, tp = confusion_matrix(self.y_test, y_pred).ravel()\n",
    "                \n",
    "                accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "                precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "                recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "                f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "                specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "                false_alarm = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
    "                \n",
    "                results.append({\n",
    "                    'Threshold': threshold,\n",
    "                    'Accuracy': accuracy,\n",
    "                    'Precision': precision,\n",
    "                    'Recall': recall,\n",
    "                    'F1-Score': f1,\n",
    "                    'Specificity': specificity,\n",
    "                    'False Alarm Rate': false_alarm,\n",
    "                    'TP': tp,\n",
    "                    'FP': fp,\n",
    "                    'TN': tn,\n",
    "                    'FN': fn\n",
    "                })\n",
    "            \n",
    "            # Create DataFrame\n",
    "            results_df = pd.DataFrame(results)\n",
    "            \n",
    "            # Plot metrics\n",
    "            plt.figure(figsize=(12, 8))\n",
    "            \n",
    "            plt.plot(results_df['Threshold'], results_df['Accuracy'], 'b-', linewidth=2, label='Accuracy')\n",
    "            plt.plot(results_df['Threshold'], results_df['Precision'], 'g-', linewidth=2, label='Precision')\n",
    "            plt.plot(results_df['Threshold'], results_df['Recall'], 'r-', linewidth=2, label='Recall')\n",
    "            plt.plot(results_df['Threshold'], results_df['F1-Score'], 'c-', linewidth=2, label='F1-Score')\n",
    "            plt.plot(results_df['Threshold'], results_df['False Alarm Rate'], 'm-', linewidth=2, label='False Alarm Rate')\n",
    "            \n",
    "            plt.grid(True, alpha=0.3)\n",
    "            plt.xlabel('Threshold', fontsize=12)\n",
    "            plt.ylabel('Metric Value', fontsize=12)\n",
    "            plt.title('Model Metrics at Different Detection Thresholds', fontsize=14)\n",
    "            plt.legend(fontsize=10)\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "            return results_df\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error calculating threshold metrics: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def plot_roc_curve(self):\n",
    "        \"\"\"\n",
    "        Plot ROC curve and calculate AUC.\n",
    "        \"\"\"\n",
    "        if self.hnids_model is None or self.X_test is None or self.y_test is None:\n",
    "            print(\"Model or test data not available. Please load model and data first.\")\n",
    "            return\n",
    "        \n",
    "        try:\n",
    "            from sklearn.metrics import roc_curve, auc\n",
    "            \n",
    "            # Get predictions\n",
    "            if not hasattr(self.hnids_model.irf_model, 'predict_proba'):\n",
    "                print(\"Model does not support probability predictions.\")\n",
    "                return\n",
    "                \n",
    "            y_proba = self.hnids_model.irf_model.predict_proba(self.X_test)[:, 1]\n",
    "            \n",
    "            # Calculate ROC curve\n",
    "            fpr, tpr, thresholds = roc_curve(self.y_test, y_proba)\n",
    "            roc_auc = auc(fpr, tpr)\n",
    "            \n",
    "            # Plot ROC curve\n",
    "            plt.figure(figsize=(10, 8))\n",
    "            \n",
    "            plt.plot(fpr, tpr, 'b-', linewidth=2, label=f'ROC curve (AUC = {roc_auc:.4f})')\n",
    "            plt.plot([0, 1], [0, 1], 'k--', linewidth=1)\n",
    "            \n",
    "            plt.xlim([0.0, 1.0])\n",
    "            plt.ylim([0.0, 1.05])\n",
    "            plt.xlabel('False Positive Rate', fontsize=12)\n",
    "            plt.ylabel('True Positive Rate', fontsize=12)\n",
    "            plt.title('Receiver Operating Characteristic (ROC) Curve', fontsize=14)\n",
    "            plt.legend(loc='lower right', fontsize=10)\n",
    "            plt.grid(True, alpha=0.3)\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "            # Print AUC value\n",
    "            print(f\"Area Under the ROC Curve (AUC): {roc_auc:.4f}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error plotting ROC curve: {e}\")\n",
    "    \n",
    "    def plot_precision_recall_curve(self):\n",
    "        \"\"\"\n",
    "        Plot Precision-Recall curve.\n",
    "        \"\"\"\n",
    "        if self.hnids_model is None or self.X_test is None or self.y_test is None:\n",
    "            print(\"Model or test data not available. Please load model and data first.\")\n",
    "            return\n",
    "        \n",
    "        try:\n",
    "            from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "            \n",
    "            # Get predictions\n",
    "            if not hasattr(self.hnids_model.irf_model, 'predict_proba'):\n",
    "                print(\"Model does not support probability predictions.\")\n",
    "                return\n",
    "                \n",
    "            y_proba = self.hnids_model.irf_model.predict_proba(self.X_test)[:, 1]\n",
    "            \n",
    "            # Calculate Precision-Recall curve\n",
    "            precision, recall, thresholds = precision_recall_curve(self.y_test, y_proba)\n",
    "            average_precision = average_precision_score(self.y_test, y_proba)\n",
    "            \n",
    "            # Plot Precision-Recall curve\n",
    "            plt.figure(figsize=(10, 8))\n",
    "            \n",
    "            plt.plot(recall, precision, 'b-', linewidth=2, \n",
    "                   label=f'Precision-Recall curve (AP = {average_precision:.4f})')\n",
    "            \n",
    "            plt.xlim([0.0, 1.0])\n",
    "            plt.ylim([0.0, 1.05])\n",
    "            plt.xlabel('Recall', fontsize=12)\n",
    "            plt.ylabel('Precision', fontsize=12)\n",
    "            plt.title('Precision-Recall Curve', fontsize=14)\n",
    "            plt.legend(loc='lower left', fontsize=10)\n",
    "            plt.grid(True, alpha=0.3)\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "            # Print Average Precision\n",
    "            print(f\"Average Precision (AP): {average_precision:.4f}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error plotting Precision-Recall curve: {e}\")\n",
    "    \n",
    "    def analyze_attack_types(self, attack_mapping):\n",
    "        \"\"\"\n",
    "        Analyze model performance on different attack types.\n",
    "        \n",
    "        Args:\n",
    "            attack_mapping: Dictionary mapping attack classes to attack types\n",
    "        \"\"\"\n",
    "        if self.hnids_model is None or self.X_test is None or self.y_test is None:\n",
    "            print(\"Model or test data not available. Please load model and data first.\")\n",
    "            return\n",
    "        \n",
    "        try:\n",
    "            # Get predictions\n",
    "            y_pred = self.hnids_model.predict(self.X_test)\n",
    "            \n",
    "            # Create DataFrame with true and predicted labels\n",
    "            results_df = pd.DataFrame({\n",
    "                'true_label': self.y_test,\n",
    "                'predicted': y_pred\n",
    "            })\n",
    "            \n",
    "            # Add attack type if mapping is provided\n",
    "            if attack_mapping is not None and hasattr(self.y_test, 'index'):\n",
    "                attack_types = []\n",
    "                for idx in self.y_test.index:\n",
    "                    attack_type = attack_mapping.get(idx, 'Unknown')\n",
    "                    attack_types.append(attack_type)\n",
    "                \n",
    "                results_df['attack_type'] = attack_types\n",
    "                \n",
    "                # Analyze performance by attack type\n",
    "                attack_type_results = {}\n",
    "                \n",
    "                for attack_type in results_df['attack_type'].unique():\n",
    "                    attack_data = results_df[results_df['attack_type'] == attack_type]\n",
    "                    \n",
    "                    # Calculate metrics\n",
    "                    accuracy = (attack_data['true_label'] == attack_data['predicted']).mean()\n",
    "                    \n",
    "                    attack_type_results[attack_type] = {\n",
    "                        'count': len(attack_data),\n",
    "                        'accuracy': accuracy\n",
    "                    }\n",
    "                \n",
    "                # Create DataFrame\n",
    "                attack_results_df = pd.DataFrame.from_dict(attack_type_results, orient='index')\n",
    "                \n",
    "                # Plot results\n",
    "                plt.figure(figsize=(12, 6))\n",
    "                \n",
    "                ax = sns.barplot(x=attack_results_df.index, y='accuracy', data=attack_results_df)\n",
    "                \n",
    "                # Add count annotations\n",
    "                for i, p in enumerate(ax.patches):\n",
    "                    attack_type = attack_results_df.index[i]\n",
    "                    count = attack_results_df.loc[attack_type, 'count']\n",
    "                    ax.annotate(f'n={count}', (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "                               ha='center', va='center', fontsize=10, color='black',\n",
    "                               xytext=(0, 5), textcoords='offset points')\n",
    "                \n",
    "                plt.xticks(rotation=45, ha='right')\n",
    "                plt.xlabel('Attack Type', fontsize=12)\n",
    "                plt.ylabel('Accuracy', fontsize=12)\n",
    "                plt.title('Model Accuracy by Attack Type', fontsize=14)\n",
    "                plt.grid(True, alpha=0.3)\n",
    "                \n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "                \n",
    "                return attack_results_df\n",
    "            else:\n",
    "                print(\"Attack mapping not provided or index not available in test data.\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error analyzing attack types: {e}\")\n",
    "            \n",
    "    def analyze_errors(self, n_samples=5):\n",
    "        \"\"\"\n",
    "        Analyze model errors by showing examples of false positives and false negatives.\n",
    "        \n",
    "        Args:\n",
    "            n_samples: Number of examples to show for each error type\n",
    "        \"\"\"\n",
    "        if self.hnids_model is None or self.X_test is None or self.y_test is None:\n",
    "            print(\"Model or test data not available. Please load model and data first.\")\n",
    "            return\n",
    "        \n",
    "        try:\n",
    "            # Get predictions\n",
    "            y_pred = self.hnids_model.predict(self.X_test)\n",
    "            \n",
    "            # Create DataFrame with results\n",
    "            results_df = pd.DataFrame({\n",
    "                'true_label': self.y_test,\n",
    "                'predicted': y_pred\n",
    "            })\n",
    "            \n",
    "            # Identify false positives and false negatives\n",
    "            false_positives = results_df[(results_df['true_label'] == 0) & (results_df['predicted'] == 1)]\n",
    "            false_negatives = results_df[(results_df['true_label'] == 1) & (results_df['predicted'] == 0)]\n",
    "            \n",
    "            # Print summary\n",
    "            print(f\"Total test samples: {len(results_df)}\")\n",
    "            print(f\"False positives (Normal classified as Intrusion): {len(false_positives)}\")\n",
    "            print(f\"False negatives (Intrusion classified as Normal): {len(false_negatives)}\")\n",
    "            \n",
    "            # Show examples of false positives\n",
    "            if len(false_positives) > 0:\n",
    "                print(\"\\n===== FALSE POSITIVES (Normal misclassified as Intrusion) =====\")\n",
    "                fp_indices = false_positives.index[:min(n_samples, len(false_positives))]\n",
    "                \n",
    "                for i, idx in enumerate(fp_indices):\n",
    "                    print(f\"\\nFalse Positive Example {i+1} (Index: {idx}):\")\n",
    "                    instance = self.X_test.loc[idx]\n",
    "                    \n",
    "                    # Show top features\n",
    "                    features_df = pd.DataFrame({'Feature': instance.index, 'Value': instance.values})\n",
    "                    features_df = features_df.sort_values('Value', ascending=False)\n",
    "                    print(features_df.head(10))\n",
    "                    \n",
    "                    # If LIME explainer is available, show explanation\n",
    "                    if 'lime' in self.explainers:\n",
    "                        print(\"\\nLIME Explanation:\")\n",
    "                        rf_model = self.hnids_model.irf_model\n",
    "                        prediction_fn = lambda x: rf_model.predict_proba(x)\n",
    "                        \n",
    "                        explanation = self.explainers['lime'].explain_instance(\n",
    "                            instance.values, prediction_fn, num_features=10\n",
    "                        )\n",
    "                        \n",
    "                        # Get features contributing to prediction\n",
    "                        lime_exp = explanation.as_list(label=1)  # For intrusion class\n",
    "                        lime_df = pd.DataFrame(lime_exp, columns=['Feature', 'Contribution'])\n",
    "                        lime_df = lime_df.sort_values('Contribution', ascending=False)\n",
    "                        print(lime_df)\n",
    "            \n",
    "            # Show examples of false negatives\n",
    "            if len(false_negatives) > 0:\n",
    "                print(\"\\n===== FALSE NEGATIVES (Intrusion misclassified as Normal) =====\")\n",
    "                fn_indices = false_negatives.index[:min(n_samples, len(false_negatives))]\n",
    "                \n",
    "                for i, idx in enumerate(fn_indices):\n",
    "                    print(f\"\\nFalse Negative Example {i+1} (Index: {idx}):\")\n",
    "                    instance = self.X_test.loc[idx]\n",
    "                    \n",
    "                    # Show top features\n",
    "                    features_df = pd.DataFrame({'Feature': instance.index, 'Value': instance.values})\n",
    "                    features_df = features_df.sort_values('Value', ascending=False)\n",
    "                    print(features_df.head(10))\n",
    "                    \n",
    "                    # If LIME explainer is available, show explanation\n",
    "                    if 'lime' in self.explainers:\n",
    "                        print(\"\\nLIME Explanation:\")\n",
    "                        rf_model = self.hnids_model.irf_model\n",
    "                        prediction_fn = lambda x: rf_model.predict_proba(x)\n",
    "                        \n",
    "                        explanation = self.explainers['lime'].explain_instance(\n",
    "                            instance.values, prediction_fn, num_features=10\n",
    "                        )\n",
    "                        \n",
    "                        # Get features contributing to prediction\n",
    "                        lime_exp = explanation.as_list(label=0)  # For normal class\n",
    "                        lime_df = pd.DataFrame(lime_exp, columns=['Feature', 'Contribution'])\n",
    "                        lime_df = lime_df.sort_values('Contribution', ascending=False)\n",
    "                        print(lime_df)\n",
    "                        \n",
    "        except Exception as e:\n",
    "            print(f\"Error analyzing model errors: {e}\")\n",
    "            \n",
    "    def save_explainer(self, filepath):\n",
    "        \"\"\"\n",
    "        Save the explainer for future use.\n",
    "        \n",
    "        Args:\n",
    "            filepath: Path to save the explainer\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Create directory if it doesn't exist\n",
    "            os.makedirs(os.path.dirname(filepath), exist_ok=True)\n",
    "            \n",
    "            # Save explainers\n",
    "            with open(filepath, 'wb') as f:\n",
    "                pickle.dump(self.explainers, f)\n",
    "                \n",
    "            print(f\"Explainer saved to {filepath}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error saving explainer: {e}\")\n",
    "            \n",
    "    def load_explainer(self, filepath):\n",
    "        \"\"\"\n",
    "        Load a previously saved explainer.\n",
    "        \n",
    "        Args:\n",
    "            filepath: Path to the saved explainer\n",
    "        \"\"\"\n",
    "        try:\n",
    "            with open(filepath, 'rb') as f:\n",
    "                self.explainers = pickle.load(f)\n",
    "                \n",
    "            print(f\"Explainer loaded from {filepath}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error loading explainer: {e}\")\n",
    "\n",
    "\n",
    "# Example usage\n",
    "def main():\n",
    "    \"\"\"Demonstrate XAI for HNIDS model.\"\"\"\n",
    "    # Load your trained HNIDS model\n",
    "    model_path = 'hnids_model.pkl'\n",
    "    \n",
    "    # Try to load previously saved model\n",
    "    try:\n",
    "        with open(model_path, 'rb') as f:\n",
    "            hnids_model = pickle.load(f)\n",
    "        \n",
    "        print(\"Model loaded successfully.\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"Model file not found. Please train a model first or specify the correct path.\")\n",
    "        return\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading model: {e}\")\n",
    "        return\n",
    "    \n",
    "    # Load test data (assuming you have this data saved)\n",
    "    try:\n",
    "        X_test = pd.read_csv('X_test.csv')\n",
    "        y_test = pd.read_csv('y_test.csv', squeeze=True)\n",
    "        \n",
    "        print(\"Test data loaded successfully.\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"Test data files not found. Please prepare your data first.\")\n",
    "        return\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading test data: {e}\")\n",
    "        return\n",
    "    \n",
    "    # Initialize explainer\n",
    "    explainer = HNIDS_Explainer(hnids_model, X_test=X_test, y_test=y_test)\n",
    "    \n",
    "    # Get feature importance\n",
    "    print(\"\\n===== Feature Importance =====\")\n",
    "    importance_df = explainer.get_feature_importance(n_top_features=15)\n",
    "    if importance_df is not None:\n",
    "        print(importance_df.head(15))\n",
    "    \n",
    "    # Initialize SHAP explainer (can take some time for large models)\n",
    "    print(\"\\n===== Initializing SHAP Explainer =====\")\n",
    "    explainer.initialize_shap_explainer()\n",
    "    \n",
    "    # Global SHAP explanation\n",
    "    print(\"\\n===== Global SHAP Explanation =====\")\n",
    "    explainer.global_shap_explanation(max_display=15)\n",
    "    \n",
    "    # Local SHAP explanation for a specific instance\n",
    "    print(\"\\n===== Local SHAP Explanation =====\")\n",
    "    explainer.local_shap_explanation(instance_idx=0, force_plot=True)\n",
    "    \n",
    "    # Initialize LIME explainer\n",
    "    print(\"\\n===== Initializing LIME Explainer =====\")\n",
    "    explainer.initialize_lime_explainer()\n",
    "    \n",
    "    # Local LIME explanation\n",
    "    print(\"\\n===== Local LIME Explanation =====\")\n",
    "    explainer.local_lime_explanation(instance_idx=0, num_features=10)\n",
    "    \n",
    "    # Partial dependence plots for top features\n",
    "    if importance_df is not None:\n",
    "        top_features = importance_df['Feature'].head(6).tolist()\n",
    "        print(f\"\\n===== Partial Dependence Plots for Top Features =====\")\n",
    "        explainer.partial_dependence_plot(top_features)\n",
    "    \n",
    "    # Feature interaction plot for top 2 features\n",
    "    if importance_df is not None and len(importance_df) >= 2:\n",
    "        feature1 = importance_df['Feature'].iloc[0]\n",
    "        feature2 = importance_df['Feature'].iloc[1]\n",
    "        print(f\"\\n===== Feature Interaction Plot: {feature1} vs {feature2} =====\")\n",
    "        explainer.feature_interaction_plot(feature1, feature2)\n",
    "    \n",
    "    # Confusion matrix\n",
    "    print(\"\\n===== Confusion Matrix =====\")\n",
    "    explainer.plot_confusion_matrix(normalized=True)\n",
    "    \n",
    "    # ROC curve\n",
    "    print(\"\\n===== ROC Curve =====\")\n",
    "    explainer.plot_roc_curve()\n",
    "    \n",
    "    # Precision-Recall curve\n",
    "    print(\"\\n===== Precision-Recall Curve =====\")\n",
    "    explainer.plot_precision_recall_curve()\n",
    "    \n",
    "    # Detection threshold metrics\n",
    "    print(\"\\n===== Detection Threshold Metrics =====\")\n",
    "    thresholds_df = explainer.get_detection_threshold_metrics()\n",
    "    if thresholds_df is not None:\n",
    "        print(thresholds_df)\n",
    "    \n",
    "    # Error analysis\n",
    "    print(\"\\n===== Error Analysis =====\")\n",
    "    explainer.analyze_errors(n_samples=3)\n",
    "    \n",
    "    # Save explainer\n",
    "    explainer.save_explainer('hnids_explainer.pkl')\n",
    "    \n",
    "    print(\"\\nXAI analysis completed.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c582a38-8080-42bc-b67f-60831b104287",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
